<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title></title>
</head>
<body>
<h1> XText: Text Extraction from Multimedia
    Documents<br>
</h1>
This is an easier way to convert piles and
piles of documents.&nbsp; From the command line, from your Java
program.<br>
<br>

<h2>Usage </h2>

<pre>
        xt = XText()
        // set various XText parameters to affect behavior.
        xt.save = True
        xt.archiveRoot = /some/path
        // if you wish to save content to disk
        //
        // Now affect files you want to convert. Add ignore types, add supported types


        // Optionally xt.clear(), change settings then xt.setup() to initialize
        // converters.   xt.defaults() is called by default and includes most common file
        // types.
        xt.ignoreFileType( 'xyz' ) // Ignores files *.xyz
        xt.setup( )

        xt.setConversionListener(  you )
        // Where 'you' is some listener you setup to process a Converted Document.
        // That is, if you do not need or want to save to disk, you process the Document object and its payload in memory.

        xt.extract_text( File )
        // a loop that iterates over File
        //
        // Now yer done.

    </pre>

The output is a stream of ConvertedDocument
objects you process using an optional ConversionListener.<br>
If you are saving files, they will appear at <b>XText().archiveRoot


</b><br>
Input files that are ZIPs will be unarchived at <b>XText().tempRoot</b>
first, but immediately deleted when extraction finishes.&nbsp;
Here it is important to use save flag + archiveRoot and/or have a
listener set.&nbsp;&nbsp; Unpacking Zip files will lead to filling
up your disk if they are not scrubbed.&nbsp; Since XText is
unpacking them internally, it is also responsible for its own
cleanup.&nbsp; Unzipped archives are deleted when extract_text( F
) routine finishes when F is a zip/tar/tar.gz, etc.<br>
<br>
TODO: nested Zip files.&nbsp; We do not unzip archives in archives
for now.<br>
<br>
Main classes:<br>

<ul>
    <li><b>XText</b> - the main program</li>
    <li><b>ConvertedDocument</b> - the main
        output
    </li>
    <li><b>iConvert</b> - interface for
        converting files
    </li>
    <li><b>iFilter</b> - interface for filtering
        files
    </li>
    <li><b>ConversionListener</b> - interface for
        any post-processor that will deal with ConvertedDocument
    </li>
</ul>
<br>
A "saved" ConvertedDocument will reside at your archiveRoot and
will consist of the format:<br>
<br>

<pre>
----------------------
{CONVERTED TEXT BODY, UTF-8 or ASCII encoded}\n
\n
{JSON metadata sheet, base64-encoded}\n
----------------------
</pre>
The intent of this format is for a number of
reasons:<br>

<ul>
    <li><b>Track meta-data
        easily.&nbsp; </b>The format keeps the metadata about the
        conversion close to the original signal.
    </li>
    <li> <b>Keep the textual content front
        and center</b>. The footer metadata follows
        to not disturb the natural order of the document.&nbsp; This
        is particularly important for natural language
        processing.&nbsp; The offsets of any tagging or annotation
        into the signal will not be altered by the presence of the
        metadata sheet that follows it.
    </li>
    <li><b>Encode properly.</b> Base64
        encoding protects the data from being disturbed by processing,
        while the JSON model is widely supported for storing key/value
        pairs
    </li>
    <li>Unix line-endings are the default, for
        consistency.<br>
    </li>
</ul>
<br>
Metadata properties tracked in the metadata header include:<br>
<br>

<table>
    <caption>Conversion Fields</caption>
    <tbody>
    <tr>
        <td style="vertical-align:top"><b>Field</b><b><br>
        </b></td>
        <td style="vertical-align:top"><b>Description</b><b><br>
        </b></td>
    </tr>
    <tr>
        <td style="vertical-align:top">title<br>
        </td>
        <td style="vertical-align:top">document title, per
            Tika.&nbsp; If null or untitled we may try to get a
            scrubbed first 100 chars.<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">author<br>
        </td>
        <td style="vertical-align:top">document author<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">subject<br>
        </td>
        <td style="vertical-align:top">subject keywords<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">filepath<br>
        </td>
        <td style="vertical-align:top">file path to
            original.&nbsp; If unzipped archive this may be irrelevant
            or at least a relative path.&nbsp;&nbsp; TODO: format may
            be: file:///&lt;archive&gt;!&lt;file&gt;<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">encoding<br>
        </td>
        <td style="vertical-align:top">native encoding<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">pub_date<br>
        </td>
        <td style="vertical-align:top">best publication date
            for the document<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">encrypted<br>
        </td>
        <td style="vertical-align:top">Yes | No<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">creator_tool<br>
        </td>
        <td style="vertical-align:top">authoring tool used to
            create the document<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">converter<br>
        </td>
        <td style="vertical-align:top">conversion class<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">conversion_date<br>
        </td>
        <td style="vertical-align:top">date of conversion<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">filtered<br>
        </td>
        <td style="vertical-align:top">True |
            False.&nbsp;&nbsp; If the content was scrubbed beyond rote
            file conversion.&nbsp; Web HTML articles are likely the
            only case now.&nbsp; HTML content that is filtered is
            converted, boiler-plate junk removed, and empty lines are
            reduced.<br>
            <br>
        </td>
    </tr>
    </tbody>
</table>
<br>

<h1>Supported Formats</h1>
<br>

<table>
    <caption>Supported Formats</caption>
    <tbody>
    <tr>
        <td style="vertical-align:top">File Extension<br>
        </td>
        <td style="vertical-align:top">Converter Class<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">.doc<br>
        </td>
        <td style="vertical-align:top">MSDocConverter<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">.html, .htm<br>
        </td>
        <td style="vertical-align:top">TikaHTMLConverter<br>
            XText.scrub_article&nbsp; = true | false to affect HTML
            scrubbing.&nbsp; Scrubbing is good for pure web content,
            but if you have HTML that originated from within your
            IntraNet, scrubbing may remove valid content.<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">.pdf<br>
        </td>
        <td style="vertical-align:top">PDFConverter makes use
            of PDFBox. This may be ported to the Tika parser.<br>
            To use <br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">MS Office files, RTF<br>
        </td>
        <td style="vertical-align:top">DefaultConverter a
            wrapper around Tika.<br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">*.txt<br>
        </td>
        <td style="vertical-align:top">Plain text files are a
            bit difficult -- the main issue here is detecting encoding
            properly.&nbsp; XText tries to detect ASCII, UTF-8 or
            other encodings as best as it can.&nbsp; ASCII/UTF-8 files
            will not be saved -- they will be read in and emitted as
            trivial ConvertedDocuments.&nbsp;&nbsp; But are never
            cached or saved to output archive set by archiveRoot.<br>
            <br>
            Short texts with low confidence of encoding will also not
            be saved/archived.&nbsp; They will be emitted though.<br>
            <br>
            Texts longer than 1KB with a encodings other than ASCII or
            UTF-8 will be transcoded (to UTF-8) and converted.<br>
            <br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">*.jpg, *.jpeg<br>
        </td>
        <td style="vertical-align:top">ImageMetadataConverter
            saves EXIF header from JPEG format.&nbsp; Special
            attention is paid to pulling out GPS Lat/Lon as a "location"
            field in metadata.<br>
            <br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top">*.eml, *.msg<br>
        </td>
        <td style="vertical-align:top">MessageConverter saves
            Email message formats (and I/O streams) as RFC822 MIME
            Messages using Java Mail API.&nbsp; Attachments are saved
            off email in XText output folder or embedded;&nbsp; Items
            are attached to ConvertedDocument as <b>children</b>.&nbsp;&nbsp;&nbsp;
            <br>
            <br>
        </td>
    </tr>
    <tr>
        <td style="vertical-align:top"><br>
        </td>
        <td style="vertical-align:top"><br>
        </td>
    </tr>
    </tbody>
</table>
<br>

<h2>Content Collectors</h2>
<p>Three content collectors are provided in
    XText 1.4:<br>
</p>
<ul>
    <li>Email client (MailClient) will traverse a
        single IMAP mailbox given the appropriate credentials.&nbsp; <br>
    </li>
    <li>Web client (WebClient) will traverse a
        web site, collecting items that might be convertable by
        XText.&nbsp; Capturing source URLs along with content
        conversion is allowed.&nbsp;&nbsp;
        ConvertedDocument.addUserProperty("url", url ) for example
        would allow the caller to save original URL along with
        conversions.
    </li>
    <li>Sharepoint client (SharepointClient) is a
        variation on the WebClient and considers the specific
        conventions of sharepoint sites, their sub-folders and views.
        <br>
    </li>
</ul>
<p>Example applications for these clients is
    still under consideration. <br>
</p>
<p><br>
</p>

</body>
</html>
